{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX8wZj6IzYL0"
      },
      "source": [
        "# IR Lab Tutorial: Lemmatization\n",
        "\n",
        "This tutorial shows how to configure and use custom lemmatizer in PyTerrier.\n",
        "\n",
        "**Attention:** The scenario below is cherry-picked to explain the concept of lemmatization with a minimal example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget https://files.webis.de/software/pyterrier-plugins/custom-terrier-token-processing-1.0-SNAPSHOT-jar-with-dependencies.jar -O /root/.pyterrier/custom-terrier-token-processing-0.0.1.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyterrier as pt\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 0)\n",
        "\n",
        "if not pt.started():\n",
        "    pt.init(boot_packages=[\"mam10eks:custom-terrier-token-processing:0.0.1\"])\n",
        "    from jnius import autoclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lemmatize(t):\n",
        "    lemmatizer = autoclass(\"org.terrier.terms.StanfordLemmatizer\")()\n",
        "    return lemmatizer.stem(t)\n",
        "\n",
        "\n",
        "print(\"are =>\", lemmatize(\"are\"))\n",
        "print(\"producer =>\", lemmatize(\"producer\"))\n",
        "print(\"produces =>\", lemmatize(\"produces\"))\n",
        "print(\"corpus =>\", lemmatize(\"corpus\"))\n",
        "print(\"corpora =>\", lemmatize(\"corpora\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stem(t):\n",
        "    stemmer = autoclass(\"org.terrier.terms.PorterStemmer\")()\n",
        "    return stemmer.stem(t)\n",
        "\n",
        "\n",
        "print(\"are =>\", stem(\"are\"))\n",
        "print(\"producer =>\", stem(\"producer\"))\n",
        "print(\"produces =>\", stem(\"produces\"))\n",
        "print(\"corpus =>\", stem(\"corpus\"))\n",
        "print(\"corpora =>\", stem(\"corpora\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = [\n",
        "    {\"docno\": \"d1\", \"text\": \"A corpus is a dataset consisting of language resources.\"},\n",
        "    {\n",
        "        \"docno\": \"d2\",\n",
        "        \"text\": \"A corpus may contain documents in a single language or multiple languages.\",\n",
        "    },\n",
        "    {\n",
        "        \"docno\": \"d3\",\n",
        "        \"text\": \"A semantic treebank is a collection of natural language sentences annotated with a meaning representation.\",\n",
        "    },\n",
        "    {\n",
        "        \"docno\": \"d4\",\n",
        "        \"text\": \"A parallel text places two translation alongside each other which is often used to train machine learning translation.\",\n",
        "    },\n",
        "]\n",
        "\n",
        "topics = pd.DataFrame(\n",
        "    [\n",
        "        {\"qid\": \"1\", \"query\": \"text corpora\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "qrels = pd.DataFrame(\n",
        "    [\n",
        "        {\"qid\": \"1\", \"docno\": \"d1\", \"relevance\": 1},\n",
        "        {\"qid\": \"1\", \"docno\": \"d2\", \"relevance\": 1},\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, stemmer=\"PorterStemmer\")\n",
        "index_ref = indexer.index(documents)\n",
        "index = pt.IndexFactory.of(index_ref)\n",
        "\n",
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
        "\n",
        "pt.Experiment([bm25], topics, qrels, eval_metrics=[\"ndcg_cut_5\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, stemmer=\"StanfordLemmatizer\")\n",
        "index_ref = indexer.index(documents)\n",
        "index = pt.IndexFactory.of(index_ref)\n",
        "\n",
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
        "\n",
        "pt.Experiment([bm25], topics, qrels, eval_metrics=[\"ndcg_cut_5\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "teaching-ir-with-shared-tasks-5m3mvcKL-py3.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
