{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX8wZj6IzYL0"
      },
      "source": [
        "# IR Lab WiSe 2023: Lemmatization\n",
        "\n",
        "This tutorial shows how to configure and use custom lemmatizer in PyTerrier.\n",
        "\n",
        "**Attention:** The scenario below is cherry-picked to explain the concept of stopword lists with a minimal example.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-10-22 21:08:58--  https://files.webis.de/software/pyterrier-plugins/custom-terrier-token-processing-1.0-SNAPSHOT-jar-with-dependencies.jar\n",
            "Resolving files.webis.de (files.webis.de)... 141.54.132.200\n",
            "Connecting to files.webis.de (files.webis.de)|141.54.132.200|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 499865236 (477M) [application/java-archive]\n",
            "Saving to: ‘/root/.pyterrier/custom-terrier-token-processing-0.0.1.jar’\n",
            "\n",
            "/root/.pyterrier/cu 100%[===================>] 476.71M  24.7MB/s    in 21s     \n",
            "\n",
            "2023-10-22 21:09:19 (22.8 MB/s) - ‘/root/.pyterrier/custom-terrier-token-processing-0.0.1.jar’ saved [499865236/499865236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://files.webis.de/software/pyterrier-plugins/custom-terrier-token-processing-1.0-SNAPSHOT-jar-with-dependencies.jar -O /root/.pyterrier/custom-terrier-token-processing-0.0.1.jar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyterrier as pt\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 0)\n",
        "\n",
        "if not pt.started():\n",
        "    pt.init(boot_packages=['mam10eks:custom-terrier-token-processing:0.0.1'])\n",
        "    from jnius import autoclass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "are => be\n",
            "producer => producer\n",
            "produces => produce\n",
            "corpora => corpus\n"
          ]
        }
      ],
      "source": [
        "def lemmatize(t):\n",
        "    lemmatizer = autoclass(\"org.terrier.terms.StanfordLemmatizer\")()\n",
        "    return lemmatizer.stem(t)\n",
        "\n",
        "print('are =>', lemmatize('are'))\n",
        "print('producer =>', lemmatize('producer'))\n",
        "print('produces =>', lemmatize('produces'))\n",
        "print('corpora =>', lemmatize('corpus'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "are => ar\n",
            "producer => produc\n",
            "produces => produc\n",
            "corpora => corpu\n"
          ]
        }
      ],
      "source": [
        "def stem(t):\n",
        "    stemmer = autoclass(\"org.terrier.terms.PorterStemmer\")()\n",
        "    return stemmer.stem(t)\n",
        "\n",
        "print('are =>', stem('are'))\n",
        "print('producer =>', stem('producer'))\n",
        "print('produces =>', stem('produces'))\n",
        "print('corpora =>', stem('corpus'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "documents = [\n",
        "    {'docno': 'd1', 'text': 'A corpus is a dataset consisting of language resources.'},\n",
        "    {'docno': 'd2', 'text': 'A corpus may contain documents in a single language or multiple languages.'},\n",
        "    {'docno': 'd3', 'text': 'A semantic treebank is a collection of natural language sentences annotated with a meaning representation.'},\n",
        "    {'docno': 'd4', 'text': 'A parallel text places two translation alongside each other which is often used to train machine learning translation.'},\n",
        "]\n",
        "\n",
        "topics = pd.DataFrame([\n",
        "    {'qid': '1', 'query': 'text corpora'},\n",
        "])\n",
        "\n",
        "qrels = pd.DataFrame([\n",
        "    {'qid': '1', 'docno': 'd1', 'relevance': 1},\n",
        "    {'qid': '1', 'docno': 'd2', 'relevance': 1},\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>ndcg_cut_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BR(BM25)</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       name  ndcg_cut_5\n",
              "0  BR(BM25)  0.0       "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, stemmer='PorterStemmer')\n",
        "index_ref = indexer.index(documents)\n",
        "index = pt.IndexFactory.of(index_ref)\n",
        "\n",
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
        "\n",
        "pt.Experiment([bm25], topics, qrels, eval_metrics=['ndcg_cut_5'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>ndcg_cut_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BR(BM25)</td>\n",
              "      <td>0.693426</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       name  ndcg_cut_5\n",
              "0  BR(BM25)  0.693426  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indexer = pt.IterDictIndexer(\"/tmp/index\", overwrite=True, stemmer='StanfordLemmatizer')\n",
        "index_ref = indexer.index(documents)\n",
        "index = pt.IndexFactory.of(index_ref)\n",
        "\n",
        "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
        "\n",
        "pt.Experiment([bm25], topics, qrels, eval_metrics=['ndcg_cut_5'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
