{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Lab WiSe 2023: Topics, Documents, and Relevance Judgments\n",
    "\n",
    "Information retrieval experiments follow the [Cranfield Paradigm](https://en.wikipedia.org/wiki/Cranfield_experiments) that states that retrieval systems are evaluated using a set of information needs (topics), documents, and relevance judgments.\n",
    "\n",
    "We will use the [ir_datasets](https://ir-datasets.com/) and [tira](https://www.tira.io/task-overview/ir-lab-jena-leipzig-sose-2023) libraries to look at some examples using the retrieval scenario of the [IR Anthology](https://ir.webis.de/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Install dependencies\n",
    "\n",
    "First, we install the libraries `tira` and `ir_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed in Google Colab, in a dev container, everything should be installed already\n",
    "!pip3 install tira ir_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the dataset and imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ir_dataset \"ir-lab-jena-leipzig-sose-2023/iranthology-20230618-training\" from tira.\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load('ir-lab-jena-leipzig-sose-2023/iranthology-20230618-training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: View first Five Topics\n",
    "\n",
    "The `dataset.queries_iter()` method creates an iterable over all topics in the dataset.\n",
    "Each topic has an `query_id`, the string that is submitted to the search engine as query (can be accessed via `default_text`), a `description` that specifies what searchers with this information need are looking for, and a `narrative` that specifies which documents are relevant and which documents are non-relevant.\n",
    "\n",
    "E.g., Topic `3` tries to identify papers that `help to recognize signs of self-harm in people's social media posts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  1\n",
      "\tText:\t\tretrieval system improving effectiveness\n",
      "\tDescrition:\tWhat papers focus on improving the effectiveness of a retrieval system?\n",
      "\tNarrative:\tRelevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.\n",
      "\n",
      "Query:  2\n",
      "\tText:\t\tmachine learning language identification\n",
      "\tDescrition:\tWhat papers are about machine learning for language identification?\n",
      "\tNarrative:\tRelevant papers include research on methods of machine learning for language identification or how to improve those methods. Papers that focus on other methods for language identification or the usaged of machine learning not for language identification are not relevant.\n",
      "\n",
      "Query:  3\n",
      "\tText:\t\tsocial media detect self-harm\n",
      "\tDescrition:\tWhich papers focus on how to recognize signs of self-harm in people's social media posts?\n",
      "\tNarrative:\tRelevant papers include research on early detection of self-harm on social media platforms such as Facebook, Instagram, Reddit, Twitter and co. Papers that addresses mental health issues like depression or anorexia are not relevant. Furthermore, papers that deal with self-harm but are not related to social media are also not relevant.\n"
     ]
    }
   ],
   "source": [
    "for query in list(dataset.queries_iter())[:3]:\n",
    "    print('\\nQuery: ', query.query_id)\n",
    "\n",
    "    print('\\tText:\\t\\t' + query.default_text())\n",
    "    print('\\tDescrition:\\t' + query.description)\n",
    "    print('\\tNarrative:\\t' + query.narrative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: View First Five Relevance Judgments\n",
    "\n",
    "The `dataset.qrels_iter()` method creates an iterable over all relevance judgments (qrels for query relevance) of the dataset.\n",
    "Each qrel entry consists of an `query_id` pointing to an topic, an `doc_id` pointing to a document, and a relevance label indicating if a document is relevant (relevance > 0) or not relevant (relevance is 0) to a query. The iteration field is \"historically unused\".\n",
    "\n",
    "E.g., the first line below indicates that document `2005.ipm_journal-ir0anthology0volumeA41A1.7` is relevant to the query `retrieval system improving effectiveness`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrecQrel(query_id='1', doc_id='2005.ipm_journal-ir0anthology0volumeA41A1.7', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='1', doc_id='2019.tois_journal-ir0anthology0volumeA37A1.2', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='1', doc_id='2008.sigirconf_conference-2008.127', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='1', doc_id='2015.ipm_journal-ir0anthology0volumeA51A5.7', relevance=0, iteration='0')\n",
      "TrecQrel(query_id='1', doc_id='2008.tois_journal-ir0anthology0volumeA27A1.1', relevance=0, iteration='0')\n"
     ]
    }
   ],
   "source": [
    "for qrel in list(dataset.qrels_iter())[:5]:\n",
    "    # Access via: qrel.query_id, qrel.doc_id, qrel.relevance\n",
    "    print(qrel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Access to documents\n",
    "\n",
    "The `dataset.docs_store()` method provides random access via the document ID to all documents of a corpus.\n",
    "\n",
    "For instance, `docs_store.get('2005.ipm_journal-ir0anthology0volumeA41A1.7')` returns the document with id `2005.ipm_journal-ir0anthology0volumeA41A1.7` that has the text `\"A probabilistic model for ... linguistic knowledge.\"`.\n",
    "\n",
    "The `dataset.docs_iter()` method creates an iterable over all documents in a corpus (can be suitable to build an index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 53673 documents.\n"
     ]
    }
   ],
   "source": [
    "print('The dataset has', len(list(dataset.docs_iter())), 'documents.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenericDoc(doc_id='2005.ipm_journal-ir0anthology0volumeA41A1.7', text='A probabilistic model for stemmer generation AbstractIn this paper we will present a language-independent probabilistic model which can automatically generate stemmers. Stemmers can improve the retrieval effectiveness of information retrieval systems, however the designing and the implementation of stemmers requires a laborious amount of effort due to the fact that documents and queries are often written or spoken in several different languages. The probabilistic model proposed in this paper aims at the development of stemmers used for several languages. The proposed model describes the mutual reinforcement relationship between stems and derivations and then provides a probabilistic interpretation. A series of experiments shows that the stemmers generated by the probabilistic model are as effective as the ones based on linguistic knowledge.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_store = dataset.docs_store()\n",
    "\n",
    "docs_store.get('2005.ipm_journal-ir0anthology0volumeA41A1.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create some Descriptive Statistics for the Relevance Judgments\n",
    "\n",
    "Next, we want to create a [Pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) that shows the proportion of relevant documents per topic.\n",
    "You can imagine a DataFrame as a table.\n",
    "\n",
    "First, we show how to use the pandas DataFrame API, second, it is on you to create this table using the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>proportion_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-2</td>\n",
       "      <td>some test query 2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>some test query 1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-3</td>\n",
       "      <td>some test query 3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id              query  proportion_relevant\n",
       "1   test-2  some test query 2                  0.4\n",
       "0   test-1  some test query 1                  0.3\n",
       "2   test-3  some test query 3                  0.2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {'query_id': 'test-1', 'query': 'some test query 1', 'proportion_relevant': 0.3},\n",
    "    {'query_id': 'test-2', 'query': 'some test query 2', 'proportion_relevant': 0.4},\n",
    "    {'query_id': 'test-3', 'query': 'some test query 3', 'proportion_relevant': 0.2},\n",
    "])\n",
    "\n",
    "df.sort_values('proportion_relevant', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., in the hypothetical example above, the query `test-2` has the highest proportion of relevant documents.\n",
    "\n",
    "Next, please create a pandas DataFrame `df` containing that reports the proportion of relevant documents per topic on the real data, using `dataset.queries_iter()` and `dataset.qrels_iter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create df using dataset.queries_iter() and dataset.qrels_iter():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Find Difficult Topics\n",
    "\n",
    "Identify the query with the lowest proportion of relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Fill this cell (e.g., via `sort_values` on the `df` from above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Find Easy Topics\n",
    "\n",
    "Identify the query with the highest proportion of relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Fill this cell (e.g., via `sort_values` on the `df` from above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Find a Topic that is not Suitable to Distinguish Retrieval Systems\n",
    "\n",
    "The goal of retrieval experiments is to seperate effective retrieval systems from ineffective retrieval systems.\n",
    "Have you an idea what topics in the dataset are not well suited to distinguish effective from ineffective systems?\n",
    "\n",
    "Please select a single topic, and describe why it is not suited to distinguish retrieval systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Add your Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Find a Topic that useful to Distinguish Retrieval Systems\n",
    "\n",
    "The goal of retrieval experiments is to seperate effective retrieval systems from ineffective retrieval systems.\n",
    "In step 8, you identified a topic that barely can distinguish effective from ineffective retrieval systems.\n",
    "\n",
    "Now, please identify a single topic that is better suited for separating retrieval systems and explain why the topic is better suited. How did you select your topic, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Add your Solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
