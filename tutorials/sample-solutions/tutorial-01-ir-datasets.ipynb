{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Lab WiSe 2023: Topics, Documents, and Relevance Judgments\n",
    "\n",
    "Information retrieval experiments follow the [Cranfield Paradigm](https://en.wikipedia.org/wiki/Cranfield_experiments) that states that retrieval systems are evaluated using a set of information needs (topics), documents, and relevance judgments.\n",
    "\n",
    "We will use the [ir_datasets](https://ir-datasets.com/) and [tira](https://www.tira.io/task-overview/ir-lab-jena-leipzig-sose-2023) libraries to look at some examples using the retrieval scenario of the [IR Anthology](https://ir.webis.de/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Install dependencies\n",
    "\n",
    "First, we install the libraries `tira` and `ir_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed in Google Colab, in a dev container, everything should be installed already\n",
    "!pip3 install tira ir_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the dataset and imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load ir_dataset \"ir-lab-jena-leipzig-sose-2023/iranthology-20230618-training\" from tira.\n"
     ]
    }
   ],
   "source": [
    "from tira.third_party_integrations import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load('ir-lab-jena-leipzig-sose-2023/iranthology-20230618-training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: View first Five Topics\n",
    "\n",
    "The `dataset.queries_iter()` method creates an iterable over all topics in the dataset.\n",
    "Each topic has an `query_id`, the string that is submitted to the search engine as query (can be accessed via `default_text`), a `description` that specifies what searchers with this information need are looking for, and a `narrative` that specifies which documents are relevant and which documents are non-relevant.\n",
    "\n",
    "E.g., Topic `3` tries to identify papers that `help to recognize signs of self-harm in people's social media posts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  1\n",
      "\tText:\t\tretrieval system improving effectiveness\n",
      "\tDescrition:\tWhat papers focus on improving the effectiveness of a retrieval system?\n",
      "\tNarrative:\tRelevant papers include research on what makes a retrieval system effective and what improves the effectiveness of a retrieval system. Papers that focus on improving something else or improving the effectiveness of a system that is not a retrieval system are not relevant.\n",
      "\n",
      "Query:  2\n",
      "\tText:\t\tmachine learning language identification\n",
      "\tDescrition:\tWhat papers are about machine learning for language identification?\n",
      "\tNarrative:\tRelevant papers include research on methods of machine learning for language identification or how to improve those methods. Papers that focus on other methods for language identification or the usaged of machine learning not for language identification are not relevant.\n",
      "\n",
      "Query:  3\n",
      "\tText:\t\tsocial media detect self-harm\n",
      "\tDescrition:\tWhich papers focus on how to recognize signs of self-harm in people's social media posts?\n",
      "\tNarrative:\tRelevant papers include research on early detection of self-harm on social media platforms such as Facebook, Instagram, Reddit, Twitter and co. Papers that addresses mental health issues like depression or anorexia are not relevant. Furthermore, papers that deal with self-harm but are not related to social media are also not relevant.\n"
     ]
    }
   ],
   "source": [
    "for query in list(dataset.queries_iter())[:3]:\n",
    "    print('\\nQuery: ', query.query_id)\n",
    "\n",
    "    print('\\tText:\\t\\t' + query.default_text())\n",
    "    print('\\tDescrition:\\t' + query.description)\n",
    "    print('\\tNarrative:\\t' + query.narrative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: View First Five Relevance Judgments\n",
    "\n",
    "The `dataset.qrels_iter()` method creates an iterable over all relevance judgments (qrels for query relevance) of the dataset.\n",
    "Each qrel entry consists of an `query_id` pointing to an topic, an `doc_id` pointing to a document, and a relevance label indicating if a document is relevant (relevance > 0) or not relevant (relevance is 0) to a query. The iteration field is \"historically unused\".\n",
    "\n",
    "E.g., the first line below indicates that document `2005.ipm_journal-ir0anthology0volumeA41A1.7` is relevant to the query `retrieval system improving effectiveness`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrecQrel(query_id='1', doc_id='2005.ipm_journal-ir0anthology0volumeA41A1.7', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='1', doc_id='2019.tois_journal-ir0anthology0volumeA37A1.2', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='1', doc_id='2008.sigirconf_conference-2008.127', relevance=1, iteration='0')\n",
      "TrecQrel(query_id='1', doc_id='2015.ipm_journal-ir0anthology0volumeA51A5.7', relevance=0, iteration='0')\n",
      "TrecQrel(query_id='1', doc_id='2008.tois_journal-ir0anthology0volumeA27A1.1', relevance=0, iteration='0')\n"
     ]
    }
   ],
   "source": [
    "for qrel in list(dataset.qrels_iter())[:5]:\n",
    "    # Access via: qrel.query_id, qrel.doc_id, qrel.relevance\n",
    "    print(qrel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Access to documents\n",
    "\n",
    "The `dataset.docs_store()` method provides random access via the document ID to all documents of a corpus.\n",
    "\n",
    "For instance, `docs_store.get('2005.ipm_journal-ir0anthology0volumeA41A1.7')` returns the document with id `2005.ipm_journal-ir0anthology0volumeA41A1.7` that has the text `\"A probabilistic model for ... linguistic knowledge.\"`.\n",
    "\n",
    "The `dataset.docs_iter()` method creates an iterable over all documents in a corpus (can be suitable to build an index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 53673 documents.\n"
     ]
    }
   ],
   "source": [
    "print('The dataset has', len(list(dataset.docs_iter())), 'documents.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenericDoc(doc_id='2005.ipm_journal-ir0anthology0volumeA41A1.7', text='A probabilistic model for stemmer generation AbstractIn this paper we will present a language-independent probabilistic model which can automatically generate stemmers. Stemmers can improve the retrieval effectiveness of information retrieval systems, however the designing and the implementation of stemmers requires a laborious amount of effort due to the fact that documents and queries are often written or spoken in several different languages. The probabilistic model proposed in this paper aims at the development of stemmers used for several languages. The proposed model describes the mutual reinforcement relationship between stems and derivations and then provides a probabilistic interpretation. A series of experiments shows that the stemmers generated by the probabilistic model are as effective as the ones based on linguistic knowledge.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_store = dataset.docs_store()\n",
    "\n",
    "docs_store.get('2005.ipm_journal-ir0anthology0volumeA41A1.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create some Descriptive Statistics for the Relevance Judgments\n",
    "\n",
    "Next, we want to create a [Pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) that shows the proportion of relevant documents per topic.\n",
    "You can imagine a DataFrame as a table.\n",
    "\n",
    "First, we show how to use the pandas DataFrame API, second, it is on you to create this table using the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "      <th>proportion_relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test-2</td>\n",
       "      <td>some test query 2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test-1</td>\n",
       "      <td>some test query 1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test-3</td>\n",
       "      <td>some test query 3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  query_id              query  proportion_relevant\n",
       "1   test-2  some test query 2                  0.4\n",
       "0   test-1  some test query 1                  0.3\n",
       "2   test-3  some test query 3                  0.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {'query_id': 'test-1', 'query': 'some test query 1', 'proportion_relevant': 0.3},\n",
    "    {'query_id': 'test-2', 'query': 'some test query 2', 'proportion_relevant': 0.4},\n",
    "    {'query_id': 'test-3', 'query': 'some test query 3', 'proportion_relevant': 0.2},\n",
    "])\n",
    "\n",
    "df.sort_values('proportion_relevant', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., in the hypothetical example above, the query `test-2` has the highest proportion of relevant documents.\n",
    "\n",
    "Next, please create a pandas DataFrame `df` containing that reports the proportion of relevant documents per topic on the real data, using `dataset.queries_iter()` and `dataset.qrels_iter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>Proportion Relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>German domain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Document scoping formula</td>\n",
       "      <td>0.069767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>68</td>\n",
       "      <td>filter ad rich documents</td>\n",
       "      <td>0.116279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Algorithm acceleration with Nvidia CUDA</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>49</td>\n",
       "      <td>exhaustivity of index</td>\n",
       "      <td>0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Inclusion of text-mining</td>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>fake news detection</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>43</td>\n",
       "      <td>Deep Neural Networks</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>entity recognition</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36</td>\n",
       "      <td>recommendation systems</td>\n",
       "      <td>0.977273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                    query  Proportion Relevant\n",
       "13  14                            German domain             0.000000\n",
       "7    8                 Document scoping formula             0.069767\n",
       "66  68                 filter ad rich documents             0.116279\n",
       "10  11  Algorithm acceleration with Nvidia CUDA             0.119048\n",
       "47  49                   exhaustivity of index              0.131579\n",
       "..  ..                                      ...                  ...\n",
       "15  16                 Inclusion of text-mining             0.926829\n",
       "31  33                      fake news detection             0.935484\n",
       "41  43                     Deep Neural Networks             0.971429\n",
       "39  41                       entity recognition             0.975000\n",
       "34  36                   recommendation systems             0.977273\n",
       "\n",
       "[68 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample solution\n",
    "\n",
    "def proportion_relevant(topic_num):\n",
    "    rel, non_rel = 0, 0\n",
    "    for qrel in dataset.qrels_iter():\n",
    "        if qrel.query_id == str(topic_num):\n",
    "            rel += 1 if qrel.relevance else 0\n",
    "            non_rel += 0 if qrel.relevance else 1\n",
    "    return rel / (rel + non_rel)\n",
    "\n",
    "df = []\n",
    "for query in dataset.queries_iter():\n",
    "    df += [{'qid': query.query_id, 'query': query.title, 'Proportion Relevant': proportion_relevant(query.query_id)}]\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df.sort_values('Proportion Relevant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Find Difficult Topics\n",
    "\n",
    "Identify the query with the lowest proportion of relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>Proportion Relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>German domain</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Document scoping formula</td>\n",
       "      <td>0.069767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>68</td>\n",
       "      <td>filter ad rich documents</td>\n",
       "      <td>0.116279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Algorithm acceleration with Nvidia CUDA</td>\n",
       "      <td>0.119048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>49</td>\n",
       "      <td>exhaustivity of index</td>\n",
       "      <td>0.131579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                                    query  Proportion Relevant\n",
       "13  14                            German domain             0.000000\n",
       "7    8                 Document scoping formula             0.069767\n",
       "66  68                 filter ad rich documents             0.116279\n",
       "10  11  Algorithm acceleration with Nvidia CUDA             0.119048\n",
       "47  49                   exhaustivity of index              0.131579"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('Proportion Relevant', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Find Easy Topics\n",
    "\n",
    "Identify the query with the highest proportion of relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>Proportion Relevant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36</td>\n",
       "      <td>recommendation systems</td>\n",
       "      <td>0.977273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>entity recognition</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>43</td>\n",
       "      <td>Deep Neural Networks</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33</td>\n",
       "      <td>fake news detection</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Inclusion of text-mining</td>\n",
       "      <td>0.926829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid                     query  Proportion Relevant\n",
       "34  36    recommendation systems             0.977273\n",
       "39  41        entity recognition             0.975000\n",
       "41  43      Deep Neural Networks             0.971429\n",
       "31  33       fake news detection             0.935484\n",
       "15  16  Inclusion of text-mining             0.926829"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('Proportion Relevant', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Find a Topic that is not Suitable to Distinguish Retrieval Systems\n",
    "\n",
    "The goal of retrieval experiments is to seperate effective retrieval systems from ineffective retrieval systems.\n",
    "Have you an idea what topics in the dataset are not well suited to distinguish effective from ineffective systems?\n",
    "\n",
    "Please select a single topic, and describe why it is not suited to distinguish retrieval systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample solution:\n",
    "\n",
    "Potential points (to be expanded):\n",
    "- Topic 14 on \"German domain\" has no relevant documents, so it can distinguish no systems\n",
    "- Topic 36 on \"recommendation systems\" has almost only relevants, so it might be not really possible to distinguish systems, as all systems should be able to almost completely fill their top-10 results with relevant documents. E.g., the paper [Too Many Relevants: Whither Cranfield Test Collections?](https://dl.acm.org/doi/10.1145/3477495.3531728) points out that collections with too many relevant documents are not really useful for system comparisons.\n",
    "\n",
    "ToDo: Add more points collected from the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Find a Topic that useful to Distinguish Retrieval Systems\n",
    "\n",
    "The goal of retrieval experiments is to seperate effective retrieval systems from ineffective retrieval systems.\n",
    "In step 8, you identified a topic that barely can distinguish effective from ineffective retrieval systems.\n",
    "\n",
    "Now, please identify a single topic that is better suited for separating retrieval systems and explain why the topic is better suited. How did you select your topic, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Solution\n",
    "\n",
    "Many points could be pointed out here. Potential ones are:\n",
    "\n",
    "- Try to guess what a typical proportion of relevant documents would be for a given task. E.g., from my own experience, I would think that for related work search, between 20% and 40% of papers would be relevant for my personal typical searches, so I would aim for any topic with a relevance proportion in that range.\n",
    "- Manual inspection: Every topic that \"looks reasonable\" is suitable?\n",
    "\n",
    "ToDo: Add more points collected from the course."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
